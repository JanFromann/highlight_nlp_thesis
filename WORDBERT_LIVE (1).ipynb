{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjLrPov1VEMm",
        "outputId": "e84d5849-0122-442b-ab68-ca96a8652faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=eabdd1fb3d798571d79175798eca2a2981286bd7ce7a33256a43096987527e91\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n",
            "Mounted at /content/drive\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install tqdm\n",
        "! pip install wandb\n",
        "\n",
        "\n",
        "# Required Libraries\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "import random\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from html import escape\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lQenkav_KaA"
      },
      "source": [
        "## LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD5XvgvFVVXt"
      },
      "outputs": [],
      "source": [
        "### ALL DATA ###\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/thesis_files/\"\n",
        "\n",
        "def save_to_pickle(data, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "# Specify file names\n",
        "X_file = folder_path + '/X_bert_word_12_all_1.pkl'\n",
        "y_file = folder_path + '/y_bert_word_12_all_1.pkl'\n",
        "attention_mask_file = folder_path + '/wordbert_attention_mask_12_all_1.pkl'\n",
        "positions_file = folder_path + '/positions_bert_word_12_all_1.pkl'  # Added positions file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo0cfV2SVXsI"
      },
      "outputs": [],
      "source": [
        "### MEDIUM ONLY DATA ###\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/thesis_files/\"\n",
        "\n",
        "def save_to_pickle(data, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "\n",
        "# New Data\n",
        "\n",
        "# Specify file names\n",
        "X_file = folder_path + '/X_bert_word_29_medium_third.pkl'\n",
        "y_file = folder_path + '/y_bert_word_29_medium_third.pkl'\n",
        "attention_mask_file = folder_path + '/wordbert_attention_mask_29_medium_third.pkl'\n",
        "positions_file = folder_path + '/positions_bert_word_29_medium_third.pkl'  # Added positions file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIQm7Lv3VZ1Y"
      },
      "outputs": [],
      "source": [
        "### LOAD DATA ###\n",
        "\n",
        "# To load the data later\n",
        "def load_from_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Load the data\n",
        "X = load_from_pickle(X_file)\n",
        "y = load_from_pickle(y_file)\n",
        "attention_masks = load_from_pickle(attention_mask_file)\n",
        "positions = load_from_pickle(positions_file)  # Load positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB96O5FEVfVc"
      },
      "outputs": [],
      "source": [
        "## CLASSES\n",
        "\n",
        "class BertForSequenceTagging(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', num_tags=4, num_BILSTM_layers=1):\n",
        "        super(BertForSequenceTagging, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
        "        self.positional_ffnn = nn.Linear(1, self.bert_model.config.hidden_size)  # New layer to process positional embeddings\n",
        "\n",
        "        # Updated LSTM to have the specified number of BiLSTM layers\n",
        "        self.word_lstm = nn.LSTM(self.bert_model.config.hidden_size, 100, num_layers=num_BILSTM_layers, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.word_output = nn.Linear(200, num_tags)\n",
        "\n",
        "    def forward(self, document_input, mask_input, positions_input):  # Added positions_input\n",
        "        bert_output = self.bert_model(document_input, attention_mask=mask_input)[0]\n",
        "        positions_output = self.positional_ffnn(positions_input.unsqueeze(-1))  # Process positional embeddings\n",
        "        bert_output = bert_output + positions_output  # Add positional embeddings to BERT output\n",
        "        lstm_output, _ = self.word_lstm(bert_output)\n",
        "        dropout_output = self.dropout(lstm_output)\n",
        "        tag_logits = self.word_output(dropout_output)\n",
        "        return tag_logits\n",
        "\n",
        "\n",
        "#class BertForSequenceTagging(nn.Module):\n",
        "#    def __init__(self, bert_model_name='bert-base-uncased', num_tags=4):\n",
        "#        super(BertForSequenceTagging, self).__init__()\n",
        "#        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
        "#        self.positional_ffnn = nn.Linear(1, self.bert_model.config.hidden_size)  # New layer to process positional embeddings\n",
        "#        self.word_lstm = nn.LSTM(self.bert_model.config.hidden_size, 100, bidirectional=True, batch_first=True)\n",
        "#        self.dropout = nn.Dropout(0.1)\n",
        "#        self.word_output = nn.Linear(200, num_tags)\n",
        "\n",
        "#    def forward(self, document_input, mask_input, positions_input):  # Added positions_input\n",
        "#        bert_output = self.bert_model(document_input, attention_mask=mask_input)[0]\n",
        "#        positions_output = self.positional_ffnn(positions_input.unsqueeze(-1))  # Process positional embeddings\n",
        "#        bert_output = bert_output + positions_output  # Add positional embeddings to BERT output\n",
        "#        lstm_output, _ = self.word_lstm(bert_output)\n",
        "#        dropout_output = self.dropout(lstm_output)\n",
        "#        tag_logits = self.word_output(dropout_output)\n",
        "#        return tag_logits\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2, ignore_index=None):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        if alpha is not None:\n",
        "            if isinstance(alpha, (list, tuple)):\n",
        "                self.alpha = torch.tensor(alpha).to(device)  # Move alpha to the device\n",
        "            elif isinstance(alpha, torch.Tensor):\n",
        "                self.alpha = alpha.to(device)  # Move alpha to the device\n",
        "        self.gamma = gamma\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # Compute the negative log-likelihood\n",
        "        if self.ignore_index is None:\n",
        "            logpt = F.cross_entropy(input, target, reduction='none')\n",
        "        else:\n",
        "            logpt = F.cross_entropy(input, target, reduction='none', ignore_index=self.ignore_index)\n",
        "\n",
        "        pt = torch.exp(-logpt)\n",
        "\n",
        "        # Compute the focal loss\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha.gather(0, target.data.view(-1))\n",
        "            logpt = logpt * at\n",
        "\n",
        "        focal_loss = (1-pt)**self.gamma * logpt\n",
        "\n",
        "        return focal_loss.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhz2YwgdV2Qo"
      },
      "outputs": [],
      "source": [
        "## FUNCTIONS\n",
        "\n",
        "SEED=42\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "def split_data(X, y, attention_masks, positions, train_size, val_size, test_sizen, random_state):\n",
        "    assert train_size + val_size + test_size == 1, \"train_size, val_size, and test_size must sum up to 1\"\n",
        "\n",
        "    X_temp, X_test, y_temp, y_test, masks_temp, masks_test, positions_temp, positions_test = train_test_split(\n",
        "        X, y, attention_masks, positions, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Adjust train_size to account for the previous split\n",
        "    train_size_adjusted = train_size / (train_size + val_size)\n",
        "    X_train, X_val, y_train, y_val, masks_train, masks_val, positions_train, positions_val = train_test_split(\n",
        "        X_temp, y_temp, masks_temp, positions_temp, test_size=1 - train_size_adjusted, random_state=random_state\n",
        "    )\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, masks_train, masks_val, masks_test, positions_train, positions_val, positions_test\n",
        "\n",
        "\n",
        "def setup_data(X, y, attention_masks, positions, train_size=0.8, val_size=0.1, test_size=0.1, batch_size=64, random_state=SEED, device=None):\n",
        "\n",
        "    # Split the data into training, validation and testing sets\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, attention_masks_train, attention_masks_val, attention_masks_test, positions_train, positions_val, positions_test = split_data(X, y, attention_masks, positions, train_size, val_size, test_size, random_state)\n",
        "    print(f'X_train len: {len(X_train)}')\n",
        "    print(f'X_val len: {len(X_val)}')\n",
        "    print(f'X_test len: {len(X_train)}')\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    X_train = torch.tensor(X_train)\n",
        "    X_val = torch.tensor(X_val)\n",
        "    X_test = torch.tensor(X_test)\n",
        "    y_train = torch.tensor(y_train)\n",
        "    y_val = torch.tensor(y_val)\n",
        "    y_test = torch.tensor(y_test)\n",
        "    attention_masks_train = torch.tensor(attention_masks_train)\n",
        "    attention_masks_val = torch.tensor(attention_masks_val)\n",
        "    attention_masks_test = torch.tensor(attention_masks_test)\n",
        "    positions_train = torch.tensor(positions_train, dtype=torch.float)  # Convert positions to float tensors\n",
        "    positions_val = torch.tensor(positions_val, dtype=torch.float)  # Convert positions to float tensors\n",
        "    positions_test = torch.tensor(positions_test, dtype=torch.float)  # Convert positions to float tensors\n",
        "\n",
        "    # If a device is not provided, use CUDA if available\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the data to the specified device\n",
        "    X_train = X_train.to(device)\n",
        "    X_val = X_val.to(device)\n",
        "    X_test = X_test.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    y_val = y_val.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    attention_masks_train = attention_masks_train.to(device)\n",
        "    attention_masks_val = attention_masks_val.to(device)\n",
        "    attention_masks_test = attention_masks_test.to(device)\n",
        "    positions_train = positions_train.to(device)  # Move positions to the GPU\n",
        "    positions_val = positions_val.to(device)  # Move positions to the GPU\n",
        "    positions_test = positions_test.to(device)  # Move positions to the GPU\n",
        "\n",
        "    # Create TensorDatasets for training, validation, and test sets\n",
        "    train_data = TensorDataset(X_train, attention_masks_train, positions_train, y_train)\n",
        "    val_data = TensorDataset(X_val, attention_masks_val, positions_val, y_val)\n",
        "    test_data = TensorDataset(X_test, attention_masks_test, positions_test, y_test)\n",
        "\n",
        "    # Set up the DataLoaders\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, y_train # y_train needed for class weight calc\n",
        "\n",
        "def calculate_class_weights(y_train, device, class_h_factor=1.0):\n",
        "    # Move the tensor to host memory first\n",
        "    y_train_cpu = y_train.cpu()\n",
        "    unique_labels, counts = np.unique(y_train_cpu, return_counts=True)\n",
        "    weights = 1.0 / counts\n",
        "    weights_dict = dict(zip(unique_labels, weights))\n",
        "\n",
        "    # Set the weight for padding or special tokens to zero\n",
        "    weights_dict[0] = 0  # assuming 0 is the label for padding/special tokens\n",
        "    weights_dict[2] *= class_h_factor\n",
        "    weights_dict[3] = 0\n",
        "\n",
        "    weights_list = [weights_dict[i] for i in range(len(weights_dict))]\n",
        "\n",
        "    class_weights = torch.tensor(weights_list).float().to(device)\n",
        "    return class_weights, weights_dict\n",
        "\n",
        "\n",
        "import wandb\n",
        "\n",
        "def setup_model(bert_model_name, num_classes, num_unfreeze_layers, device=None, num_BILSTM_layers=1):\n",
        "    # Model creation\n",
        "    model = BertForSequenceTagging(bert_model_name=bert_model_name, num_tags=num_classes, num_BILSTM_layers=num_BILSTM_layers)\n",
        "\n",
        "    # If a device is not provided, use CUDA if available\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Freeze all parameters first\n",
        "    for name, param in model.named_parameters():\n",
        "        # Do not freeze the parameters of the new layers\n",
        "        if \"bert_model\" in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Unfreeze the last 'num_unfreeze_layers' layers\n",
        "    for i in range(-num_unfreeze_layers, 0, 1):\n",
        "        for param in model.bert_model.encoder.layer[i].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    # Log model information to Weights and Biases\n",
        "    wandb.log({'model_name': bert_model_name, 'num_unfreeze_layers': num_unfreeze_layers})\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def set_up_loss_optimizer(model, train_dataloader, num_epochs, learning_rate, eps, loss_type, use_scheduler=True, num_warmup_steps=0, class_weights=None, alpha=None, gamma=None):\n",
        "\n",
        "\n",
        "    # Only optimize parameters that require gradients (i.e., unfrozen parameters)\n",
        "    optimizer = AdamW([param for param in model.parameters() if param.requires_grad], lr=learning_rate, eps=eps)\n",
        "\n",
        "    if loss_type.lower() == 'focal':\n",
        "        # Use the provided alpha and gamma parameters for the Focal Loss\n",
        "        loss_function = FocalLoss(alpha=alpha, gamma=gamma)\n",
        "    elif loss_type.lower() == 'cross_entropy':\n",
        "        loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid loss_type. Expected 'focal' or 'cross_entropy'\")\n",
        "\n",
        "    if use_scheduler:\n",
        "        total_steps = len(train_dataloader) * num_epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    return optimizer, loss_function, scheduler\n",
        "\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "\n",
        "def compute_masked_loss(model, input_ids, attention_masks, positions, labels, loss_function):\n",
        "    outputs = model(input_ids, attention_masks, positions)\n",
        "    #print(f\"ComputeL_outouts_shape: {outputs.shape}\")\n",
        "    mask = ((labels != 0) & (labels != 3))\n",
        "    masked_outputs = outputs[mask]\n",
        "    #print(f\"ComputeL_masked_outouts_shape: {masked_outputs.shape}\")\n",
        "    masked_targets = labels[mask]\n",
        "    #print(f\"ComputeL_masked_targets_shape: {masked_targets.shape}\")\n",
        "    loss = loss_function(masked_outputs.view(-1, masked_outputs.shape[-1]), masked_targets.view(-1))\n",
        "    return loss, masked_outputs\n",
        "\n",
        "def train_model(model, train_dataloader, optimizer, loss_function, epoch, scheduler=None):\n",
        "    epoch += 1 # to not zero index\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    total_recall = 0\n",
        "    total_steps = 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f'Train Epoch {epoch}')\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # Clear any previously calculated gradients before performing a backward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids, attention_masks, positions, labels = batch\n",
        "\n",
        "        # Perform a forward pass. This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`.\n",
        "        loss, masked_outputs = compute_masked_loss(model, input_ids, attention_masks, positions, labels, loss_function)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches to calculate the average loss at the end\n",
        "        # `loss` is a Tensor containing a single value; the `.item()` function just returns the Python value from the tensor\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Create mask for ignoring the padding and special tokens when computing the accuracy and recall\n",
        "        mask = ((labels != 0) & (labels != 3)).view(-1)  # assuming 0 and 3 are the labels for padding and special tokens\n",
        "        masked_labels = labels.view(-1)[mask]\n",
        "\n",
        "        # Convert the model output to the predicted labels\n",
        "        predicted = torch.argmax(masked_outputs, 1)\n",
        "\n",
        "        # Calculate accuracy and recall\n",
        "        total_accuracy += accuracy_score(masked_labels.cpu().numpy(), predicted.cpu().numpy())\n",
        "        total_recall += recall_score(masked_labels.cpu().numpy(), predicted.cpu().numpy(), average='micro')\n",
        "\n",
        "        total_steps += 1\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\n",
        "            'epoch': epoch,\n",
        "            'Train/Loss': total_loss / total_steps,\n",
        "            'Train/Accuracy': total_accuracy / total_steps,\n",
        "            'Train/Recall': total_recall / total_steps\n",
        "        })\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({'loss': total_loss / total_steps,\n",
        "                                  'accuracy': total_accuracy / total_steps,\n",
        "                                  'recall': total_recall / total_steps})\n",
        "\n",
        "    # Compute the average loss over the training data.\n",
        "    avg_train_loss = total_loss / total_steps\n",
        "    avg_train_accuracy = total_accuracy / total_steps\n",
        "    avg_train_recall = total_recall / total_steps\n",
        "\n",
        "    return avg_train_loss, avg_train_accuracy, avg_train_recall\n",
        "\n",
        "def validate_model(model, val_dataloader, loss_function, epoch):\n",
        "    epoch += 1 # to not zero index\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    total_recall = 0\n",
        "    total_steps = 0\n",
        "\n",
        "    progress_bar = tqdm(val_dataloader, desc=f'Validate Epoch {epoch}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            input_ids, attention_masks, positions, labels = batch\n",
        "            loss, masked_outputs = compute_masked_loss(model, input_ids, attention_masks, positions, labels, loss_function)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Create mask for ignoring the padding and special tokens when computing the accuracy and recall\n",
        "            mask = ((labels != 0) & (labels != 3)).view(-1)  # assuming 0 and 3 are the labels for padding and special tokens\n",
        "            masked_labels = labels.view(-1)[mask]\n",
        "\n",
        "            # Convert the model output to the predicted labels\n",
        "            predicted = torch.argmax(masked_outputs, 1)\n",
        "\n",
        "            # Flatten the labels and predictions and detach them before converting to numpy arrays\n",
        "            masked_labels = masked_labels.view(-1).detach().cpu().numpy()\n",
        "            predicted = predicted.view(-1).detach().cpu().numpy()\n",
        "\n",
        "            # Calculate accuracy and recall\n",
        "            total_accuracy += accuracy_score(masked_labels, predicted)\n",
        "            total_recall += recall_score(masked_labels, predicted, average='micro')\n",
        "\n",
        "            total_steps += 1\n",
        "\n",
        "            # Log metrics to wandb\n",
        "            wandb.log({\n",
        "                'epoch': epoch,\n",
        "                'Validate/Loss': total_loss / total_steps,\n",
        "                'Validate/Accuracy': total_accuracy / total_steps,\n",
        "                'Validate/Recall': total_recall / total_steps\n",
        "            })\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({'loss': total_loss / total_steps,\n",
        "                                      'accuracy': total_accuracy / total_steps,\n",
        "                                      'recall': total_recall / total_steps})\n",
        "\n",
        "    # Compute the average loss, accuracy, and recall over the validation data.\n",
        "    avg_val_loss = total_loss / total_steps\n",
        "    avg_val_accuracy = total_accuracy / total_steps\n",
        "    avg_val_recall = total_recall / total_steps\n",
        "\n",
        "    return avg_val_loss, avg_val_accuracy, avg_val_recall\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, test_dataloader, loss_function):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    total_recall = 0\n",
        "    total_steps = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    progress_bar = tqdm(test_dataloader, desc='Test')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            input_ids, attention_masks, positions, labels = batch\n",
        "            loss, masked_outputs = compute_masked_loss(model, input_ids, attention_masks, positions, labels, loss_function)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Create mask for ignoring the padding and special tokens when computing the accuracy and recall\n",
        "            mask = ((labels != 0) & (labels != 3)).view(-1)  # assuming 0 and 3 are the labels for padding and special tokens\n",
        "            masked_labels = labels.view(-1)[mask]\n",
        "\n",
        "            # Convert the model output to the predicted labels\n",
        "            predicted = torch.argmax(masked_outputs, 1)\n",
        "\n",
        "            # Flatten the labels and predictions and detach them before converting to numpy arrays\n",
        "            masked_labels = masked_labels.view(-1).detach().cpu().numpy()\n",
        "            predicted = predicted.view(-1).detach().cpu().numpy()\n",
        "\n",
        "            # Append the current batch's labels and predictions to the accumulators\n",
        "            all_labels.extend(masked_labels)\n",
        "            all_predictions.extend(predicted)\n",
        "\n",
        "            # Calculate accuracy and recall\n",
        "            total_accuracy += accuracy_score(masked_labels, predicted)\n",
        "            total_recall += recall_score(masked_labels, predicted, average='micro')\n",
        "\n",
        "            total_steps += 1\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({'loss': total_loss / total_steps,\n",
        "                                      'accuracy': total_accuracy / total_steps,\n",
        "                                      'recall': total_recall / total_steps})\n",
        "\n",
        "    # Compute the average loss, accuracy, and recall over the test data.\n",
        "    avg_test_loss = total_loss / total_steps\n",
        "    avg_test_accuracy = total_accuracy / total_steps\n",
        "    avg_test_recall = total_recall / total_steps\n",
        "\n",
        "    # Calculate and print the classification report\n",
        "    classification_report_str = classification_report(all_labels, all_predictions, zero_division=1)\n",
        "    classification_report_dict = classification_report(all_labels, all_predictions, zero_division=1, output_dict=True)\n",
        "\n",
        "    # Log metrics and the classification report to wandb\n",
        "    wandb.log({\n",
        "        'Test/Loss': avg_test_loss,\n",
        "        'Test/Accuracy': avg_test_accuracy,\n",
        "        'Test/Recall': avg_test_recall,\n",
        "        'Test/Classification Report': classification_report_dict\n",
        "    })\n",
        "\n",
        "    # Convert the classification report to a text plot\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.text(0.5, 0.5, classification_report_str, horizontalalignment='center', verticalalignment='center')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Save the plot to a BytesIO object\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    buf.seek(0)\n",
        "\n",
        "    # Load the image from the BytesIO object and log it to wandb\n",
        "    img = Image.open(buf)\n",
        "    wandb.log({'Test/Classification Report Image': [wandb.Image(img, caption='Classification Report')]})\n",
        "\n",
        "    # Close the BytesIO object\n",
        "    buf.close()\n",
        "\n",
        "    return avg_test_loss, avg_test_accuracy, avg_test_recall, all_labels, all_predictions\n",
        "\n",
        "\n",
        "def save_model_to_drive(model, model_name):\n",
        "    # Set the save path\n",
        "    save_path = \"/content/drive/MyDrive/thesis_files/WORDBERT/\" + model_name\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Model saved at {save_path}\")\n",
        "\n",
        "\n",
        "def html_highlight(tokens, labels, color=\"yellow\", sentences_per_paragraph=5, filter_special_tokens=False, merge_subwords=False):\n",
        "    \"\"\"\n",
        "    Generate HTML for the given tokens and labels.\n",
        "\n",
        "    Args:\n",
        "        tokens (List[str]): The list of tokens.\n",
        "        labels (List[str]): The corresponding list of labels.\n",
        "        color (str, optional): The highlight color for 'highlight' labels.\n",
        "            Defaults to \"yellow\".\n",
        "        sentences_per_paragraph (int, optional): The number of sentences per paragraph.\n",
        "            Defaults to 5.\n",
        "        filter_special_tokens (bool, optional): If True, ignores special tokens like [CLS], [SEP], [PAD].\n",
        "            Defaults to False.\n",
        "        merge_subwords (bool, optional): If True, merge subwords with '##' with the previous word.\n",
        "            Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated HTML string.\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    sentence_count = 0\n",
        "    for token, label in zip(tokens, labels):\n",
        "        # Ignore special tokens\n",
        "        if filter_special_tokens and token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
        "            continue\n",
        "\n",
        "        if merge_subwords and token.startswith('##'):\n",
        "            token = token[2:]  # remove '##'\n",
        "            html[-1] = html[-1] + token  # merge with previous token\n",
        "            continue\n",
        "        else:\n",
        "            if label == 'highlight':\n",
        "                html.append(f'<mark style=\"background-color: {color};\">{escape(token)}</mark>')\n",
        "            else:\n",
        "                html.append(escape(token))\n",
        "\n",
        "        if token.endswith('.'):\n",
        "            sentence_count += 1\n",
        "            if sentence_count == sentences_per_paragraph:\n",
        "                html.append('<br/><br/>')\n",
        "                sentence_count = 0\n",
        "\n",
        "    html_text = ' '.join(html)\n",
        "\n",
        "    # Add HTML and CSS to resemble Medium blog post style\n",
        "    html_text = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "    <style>\n",
        "    body {{\n",
        "        font-family: 'Times New Roman', Times, serif;\n",
        "        color: #444;\n",
        "        background-color: #FAFAFA;\n",
        "        margin: 0;\n",
        "        padding: 0;\n",
        "    }}\n",
        "    .content {{\n",
        "        max-width: 800px;\n",
        "        margin: 0 auto;\n",
        "        padding: 2em;\n",
        "        font-size: 18px;\n",
        "        line-height: 1.6;\n",
        "    }}\n",
        "    mark {{\n",
        "        background-color: #FFF9C4;\n",
        "        padding: 0.2em;\n",
        "    }}\n",
        "    </style>\n",
        "    </head>\n",
        "    <body>\n",
        "    <div class=\"content\">\n",
        "    {html_text}\n",
        "    </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    return html_text\n",
        "\n",
        "\n",
        "def infer(document):\n",
        "    max_sentence_length = 512  # As previously used in tokenization\n",
        "\n",
        "    # Tokenize the document\n",
        "    document_words = tokenizer.encode(document, add_special_tokens=False)\n",
        "\n",
        "    # Calculate positions\n",
        "    document_positions = [i / len(document_words) for i in range(len(document_words))]  # Normalize positions\n",
        "\n",
        "    # Split document into windows of max_sentence_length\n",
        "    segments = []\n",
        "    positions_segments = []\n",
        "    for i in range(0, len(document_words), max_sentence_length - 2):\n",
        "        words_window = document_words[i:i + max_sentence_length - 2]\n",
        "        positions_window = document_positions[i:i + max_sentence_length - 2]\n",
        "\n",
        "        # Add special tokens\n",
        "        words_window = [tokenizer.cls_token_id] + words_window + [tokenizer.sep_token_id]\n",
        "        positions_window = [-1] + positions_window + [-1]\n",
        "\n",
        "        # Create attention mask\n",
        "        attention_mask = [1] * len(words_window)\n",
        "\n",
        "        # Pad sequences\n",
        "        if len(words_window) < max_sentence_length:\n",
        "            padding_length = max_sentence_length - len(words_window)\n",
        "            words_window += [tokenizer.pad_token_id] * padding_length\n",
        "            positions_window += [-1] * padding_length\n",
        "            attention_mask += [0] * padding_length\n",
        "\n",
        "        segments.append((words_window, attention_mask))\n",
        "        positions_segments.append(positions_window)\n",
        "\n",
        "    # Initialize lists to store tokens and labels for all segments\n",
        "    all_tokens = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Apply inference to each segment\n",
        "    for segment, positions in zip(segments, positions_segments):\n",
        "        # Convert lists to tensors and move them to the same device as the model\n",
        "        segment_tokens = torch.tensor([segment[0]]).to(device)\n",
        "        attention_mask = torch.tensor([segment[1]]).to(device)\n",
        "        positions = torch.tensor([positions], dtype=torch.float).to(device)  # Convert positions to float tensors\n",
        "\n",
        "        # Run the text through the model and get the predicted classes\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(segment_tokens, attention_mask, positions) # adapt here for nopos / pos , positions\n",
        "\n",
        "        # Get the most likely tag for each token\n",
        "        _, predicted = torch.max(outputs, 2)\n",
        "\n",
        "        # Map predicted token indices back to their corresponding labels\n",
        "        predicted_indices = predicted[0].cpu().numpy()\n",
        "        labels = [list(label_tokenizer.word_index.keys())[list(label_tokenizer.word_index.values()).index(index)] for index in predicted_indices]\n",
        "\n",
        "        # Append the tokens and their predicted labels to the respective lists\n",
        "        tokens = tokenizer.convert_ids_to_tokens(segment_tokens[0])\n",
        "        all_tokens.extend(tokens)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    # Return the complete lists of tokens and labels\n",
        "    return all_tokens, all_labels\n",
        "\n",
        "\n",
        "def inference_testing(json_file_path, model, name):\n",
        "    html_files = []\n",
        "\n",
        "    # Load data from json\n",
        "    data_df = pd.read_json(json_file_path)\n",
        "\n",
        "    # Get current date\n",
        "    date_str = datetime.date.today().strftime('%Y%m%d')\n",
        "\n",
        "    # Create a new directory for this run's HTML files\n",
        "    output_dir = f'/content/drive/MyDrive/thesis_files/WORDBERT/{name}_{date_str}'\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Iterate over documents in the DataFrame\n",
        "    for idx, row in data_df.iterrows():\n",
        "        title = row['title']\n",
        "        content = row['content']\n",
        "\n",
        "        # Run inference with the model\n",
        "        tokens, labels = infer(content)\n",
        "\n",
        "        # Generate HTML document\n",
        "        html_content = html_highlight(tokens, labels)\n",
        "\n",
        "        # Generate HTML file path\n",
        "        html_file_path = os.path.join(output_dir, f'{title}.html')\n",
        "\n",
        "        # Save HTML to a file\n",
        "        with open(html_file_path, 'w') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        # Add HTML file path to the list\n",
        "        html_files.append(html_file_path)\n",
        "\n",
        "    return html_files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDG-Z3LQc-dk"
      },
      "outputs": [],
      "source": [
        "## WHAT TO TEST\n",
        "\n",
        "# Medium / All\n",
        "\n",
        "# class_h_factor: sq root, 1, 2, 5, 10\n",
        "\n",
        "# num_epochs: 3, 5, 10\n",
        "\n",
        "# learning_rate: 0.001, 0.0001\n",
        "\n",
        "# alpha: 0.1/0.9, 0.01/0.99, 0.25/0.75\n",
        "# gamma: 2, 3, 4\n",
        "\n",
        "# use_scheduler: True / False\n",
        "\n",
        "# LSTM layers: 1 / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3-5ZGMG7VQsi",
        "outputId": "bddbece9-901a-42c3-b863-1c9498d34401"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjf-frommann\u001b[0m (\u001b[33mbitdat-com\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230815_115925-rmyy26j1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bitdat-com/WORDBERT_LIVE/runs/rmyy26j1' target=\"_blank\">r-live_CE_H1_2L_3p_2unfreeze_fulldata_01</a></strong> to <a href='https://wandb.ai/bitdat-com/WORDBERT_LIVE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/bitdat-com/WORDBERT_LIVE' target=\"_blank\">https://wandb.ai/bitdat-com/WORDBERT_LIVE</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/bitdat-com/WORDBERT_LIVE/runs/rmyy26j1' target=\"_blank\">https://wandb.ai/bitdat-com/WORDBERT_LIVE/runs/rmyy26j1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## SETUP\n",
        "\n",
        "\n",
        "# Set up your Weights & Biases project\n",
        "run_name = \"r-live_CE_H1_2L_3p_2unfreeze_fulldata_01\"\n",
        "wandb.init(project=\"WORDBERT_LIVE\", name=run_name)\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "wandb.log({'Device': str(device)})\n",
        "\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyon75OM_TDt"
      },
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 280,
          "referenced_widgets": [
            "1aa1c1e9a0ce405dbc880b5b83d748ed",
            "a0d7efd1cd5c47989a678db4de76dbe9",
            "ab3a3b806917490cbea384ea1e9989b8",
            "b27fa3b0206f413a91c64ea36f4df0e3",
            "42b1e509702240328c3816e16c165dd6",
            "5240b308e7de4f72a691483e36d41d62",
            "eb9657b19cad46e1b29b63d902c1fa65",
            "ee53e5ebfd244fe2b90261d3e01b82ae",
            "a42687dbc6f640e2b1b8b007035ebbfb",
            "f3501f80829443f8b3ce326e7bcf4bae",
            "9e01192f71ef4c628abb7f9c8f85803a",
            "0eb236aec13b4742afca267c84812b3c",
            "d181caed753f4ffeb347a290cf228b77",
            "7c4ee79b87fa405ab41742d86ccd8153",
            "cd24193081f5457eba6af09e80296ecd",
            "8d00f35fbbdf431c961e74484e3b5235",
            "d3fb20ba0ced431f8f644f966c8943f2",
            "06ff06410d7a4793ace2299009fd803b",
            "1f05e2498acc422487e34650d4a33228",
            "7e8f265e8d4145a198cfb9d562f1e323",
            "f72fdd89d2b34c00b2b1746f91a7c24d",
            "ad858c7978934dbab457a02dd14e2d3b",
            "62aea6e54aae4c08996ea2893a01eacc",
            "1d1f6083be0944c583c45b3b22992331"
          ]
        },
        "id": "FjzTLOnoZja0",
        "outputId": "ec3fb4ab-6542-4a34-c888-6002c103d1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train len: 102010\n",
            "X_val len: 12752\n",
            "X_test len: 102010\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa1c1e9a0ce405dbc880b5b83d748ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eb236aec13b4742afca267c84812b3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Train Epoch 1: 100%|██████████| 1594/1594 [21:33<00:00,  1.23it/s, loss=0.505, accuracy=0.826, recall=0.826]\n",
            "Validate Epoch 1: 100%|██████████| 200/200 [01:55<00:00,  1.73it/s, loss=0.507, accuracy=0.893, recall=0.893]\n",
            "Train Epoch 2: 100%|██████████| 1594/1594 [21:31<00:00,  1.23it/s, loss=0.463, accuracy=0.847, recall=0.847]\n",
            "Validate Epoch 2: 100%|██████████| 200/200 [01:55<00:00,  1.73it/s, loss=0.482, accuracy=0.89, recall=0.89]\n",
            "Train Epoch 3: 100%|██████████| 1594/1594 [21:29<00:00,  1.24it/s, loss=0.441, accuracy=0.854, recall=0.854]\n",
            "Validate Epoch 3: 100%|██████████| 200/200 [01:55<00:00,  1.73it/s, loss=0.438, accuracy=0.833, recall=0.833]\n",
            "Test: 100%|██████████| 200/200 [01:56<00:00,  1.72it/s, loss=0.418, accuracy=0.835, recall=0.835]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62aea6e54aae4c08996ea2893a01eacc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1f6083be0944c583c45b3b22992331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at /content/drive/MyDrive/thesis_files/WORDBERT/r-live_CE_H1_2L_3p_2unfreeze_fulldata_01.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test/Accuracy</td><td>▁</td></tr><tr><td>Test/Loss</td><td>▁</td></tr><tr><td>Test/Recall</td><td>▁</td></tr><tr><td>Train/Accuracy</td><td>▁▄▅▅▅▅▅▅▅▅▅▅▄█▇▅▆▆▆▅▅▅▅▆▆▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Train/Loss</td><td>█▆▄▄▄▄▄▄▃▃▃▃▃▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>Train/Recall</td><td>▁▄▅▅▅▅▅▅▅▅▅▅▄█▇▅▆▆▆▅▅▅▅▆▆▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Validate/Accuracy</td><td>█▇████████████▇█▇▇███▇█████▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Validate/Loss</td><td>██▇▆▆▆▆▆▇▇▇▇▇▇▆▅▅▅▅▅▄▅▅▅▅▅▅▁▂▂▂▂▂▁▁▂▂▂▂▃</td></tr><tr><td>Validate/Recall</td><td>█▇████████████▇█▇▇███▇█████▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>num_unfreeze_layers</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Device</td><td>cuda</td></tr><tr><td>Test/Accuracy</td><td>0.83531</td></tr><tr><td>Test/Loss</td><td>0.41841</td></tr><tr><td>Test/Recall</td><td>0.83531</td></tr><tr><td>Train/Accuracy</td><td>0.85362</td></tr><tr><td>Train/Loss</td><td>0.44122</td></tr><tr><td>Train/Recall</td><td>0.85362</td></tr><tr><td>Validate/Accuracy</td><td>0.83312</td></tr><tr><td>Validate/Loss</td><td>0.43752</td></tr><tr><td>Validate/Recall</td><td>0.83312</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>model_name</td><td>bert-base-uncased</td></tr><tr><td>num_unfreeze_layers</td><td>2</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">r-live_CE_H1_2L_3p_2unfreeze_fulldata_01</strong> at: <a href='https://wandb.ai/bitdat-com/WORDBERT_LIVE/runs/rmyy26j1' target=\"_blank\">https://wandb.ai/bitdat-com/WORDBERT_LIVE/runs/rmyy26j1</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 5 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230815_115925-rmyy26j1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## RUN\n",
        "\n",
        "# setting seed for PyTorch\n",
        "set_seed(SEED)\n",
        "wandb.config.seed = SEED\n",
        "\n",
        "# Hyperparameters\n",
        "bert_model_name='bert-base-uncased'\n",
        "\n",
        "data_set_type='all' # 'all' or 'medium'\n",
        "\n",
        "loss_type='cross_entropy' # 'focal' or 'cross_entropy'\n",
        "\n",
        "train_size=0.8\n",
        "val_size=0.1\n",
        "test_size=0.1\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs=3\n",
        "\n",
        "class_h_factor = 1\n",
        "num_unfreeze_layers = 2\n",
        "\n",
        "focal_alpha=[0,0.1,0.9,0]\n",
        "focal_gamma=2.0\n",
        "\n",
        "use_scheduler=False\n",
        "learning_rate=0.001\n",
        "eps_rate=1e-8\n",
        "\n",
        "num_BILSTM_layers=2\n",
        "\n",
        "# Log all important hyperparameters\n",
        "wandb.config.update({\n",
        "    'bert_model_name': bert_model_name,\n",
        "    'loss_type': loss_type,\n",
        "    'train_size': train_size,\n",
        "    'val_size': val_size,\n",
        "    'test_size': test_size,\n",
        "    'batch_size': batch_size,\n",
        "    'num_epochs': num_epochs,\n",
        "    'class_h_factor': class_h_factor,\n",
        "    'num_unfreeze_layers': num_unfreeze_layers,\n",
        "    'focal_alpha': focal_alpha,\n",
        "    'focal_gamma': focal_gamma,\n",
        "    'use_scheduler': use_scheduler,\n",
        "    'learning_rate': learning_rate,\n",
        "    'eps_rate': eps_rate,\n",
        "    'data_set_type' : data_set_type,\n",
        "    'num_BILSTM_layers' : num_BILSTM_layers\n",
        "})\n",
        "\n",
        "# Set-up data & data loaders\n",
        "train_dataloader, val_dataloader, test_dataloader, y_train = setup_data(X, y, attention_masks, positions, train_size=train_size, val_size=val_size, test_size=test_size, batch_size=batch_size, random_state=SEED)\n",
        "\n",
        "# Class weights calculation\n",
        "class_weights, weights_dict = calculate_class_weights(y_train, device, class_h_factor)\n",
        "\n",
        "model = setup_model(bert_model_name=bert_model_name, num_classes=4, num_unfreeze_layers=num_unfreeze_layers, num_BILSTM_layers=num_BILSTM_layers)\n",
        "\n",
        "optimizer, loss_function, scheduler = set_up_loss_optimizer(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    num_epochs=num_epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    eps=eps_rate,\n",
        "    loss_type=loss_type,\n",
        "    use_scheduler=use_scheduler,\n",
        "    class_weights=class_weights,\n",
        "    alpha=focal_alpha,  # For Focal Loss\n",
        "    gamma=focal_gamma    # For Focal Loss\n",
        ")\n",
        "\n",
        "\n",
        "# Train and validate the model for the specified number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    train_model(model, train_dataloader, optimizer, loss_function, epoch, scheduler)  # add epoch back in?\n",
        "\n",
        "    validate_model(model, val_dataloader,loss_function, epoch)\n",
        "\n",
        "\n",
        "# Test the model\n",
        "test_model(model, test_dataloader, loss_function)\n",
        "\n",
        "\n",
        "\n",
        "# setup tokenizer for inference\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "label_tokenizer = Tokenizer(filters='', lower=False)\n",
        "\n",
        "# Explicitly set the word_index\n",
        "label_tokenizer.word_index = {'normaltext': 1, 'highlight': 2}\n",
        "# This assumes 'X' is used for subword tokens and 'PAD' is used for padding tokens\n",
        "label_tokenizer.word_index['X'] = len(label_tokenizer.word_index) + 1\n",
        "label_tokenizer.word_index['PAD'] = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# save the model\n",
        "model_name = run_name + '.pt'\n",
        "save_model_to_drive(model, model_name) # set-up\n",
        "\n",
        "\n",
        "html_files = inference_testing('/content/drive/MyDrive/thesis_files/inference_docs_file.json', model, run_name)\n",
        "\n",
        "\n",
        "# Upload each HTML file to Weights & Biases\n",
        "for file in html_files:\n",
        "    wandb.save(file)\n",
        "\n",
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06ff06410d7a4793ace2299009fd803b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eb236aec13b4742afca267c84812b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d181caed753f4ffeb347a290cf228b77",
              "IPY_MODEL_7c4ee79b87fa405ab41742d86ccd8153",
              "IPY_MODEL_cd24193081f5457eba6af09e80296ecd"
            ],
            "layout": "IPY_MODEL_8d00f35fbbdf431c961e74484e3b5235"
          }
        },
        "1aa1c1e9a0ce405dbc880b5b83d748ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d7efd1cd5c47989a678db4de76dbe9",
              "IPY_MODEL_ab3a3b806917490cbea384ea1e9989b8",
              "IPY_MODEL_b27fa3b0206f413a91c64ea36f4df0e3"
            ],
            "layout": "IPY_MODEL_42b1e509702240328c3816e16c165dd6"
          }
        },
        "1f05e2498acc422487e34650d4a33228": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b1e509702240328c3816e16c165dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5240b308e7de4f72a691483e36d41d62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4ee79b87fa405ab41742d86ccd8153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f05e2498acc422487e34650d4a33228",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e8f265e8d4145a198cfb9d562f1e323",
            "value": 440449768
          }
        },
        "7e8f265e8d4145a198cfb9d562f1e323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d00f35fbbdf431c961e74484e3b5235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e01192f71ef4c628abb7f9c8f85803a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0d7efd1cd5c47989a678db4de76dbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5240b308e7de4f72a691483e36d41d62",
            "placeholder": "​",
            "style": "IPY_MODEL_eb9657b19cad46e1b29b63d902c1fa65",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a42687dbc6f640e2b1b8b007035ebbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab3a3b806917490cbea384ea1e9989b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee53e5ebfd244fe2b90261d3e01b82ae",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a42687dbc6f640e2b1b8b007035ebbfb",
            "value": 570
          }
        },
        "ad858c7978934dbab457a02dd14e2d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b27fa3b0206f413a91c64ea36f4df0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3501f80829443f8b3ce326e7bcf4bae",
            "placeholder": "​",
            "style": "IPY_MODEL_9e01192f71ef4c628abb7f9c8f85803a",
            "value": " 570/570 [00:00&lt;00:00, 29.5kB/s]"
          }
        },
        "cd24193081f5457eba6af09e80296ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72fdd89d2b34c00b2b1746f91a7c24d",
            "placeholder": "​",
            "style": "IPY_MODEL_ad858c7978934dbab457a02dd14e2d3b",
            "value": " 440M/440M [00:02&lt;00:00, 201MB/s]"
          }
        },
        "d181caed753f4ffeb347a290cf228b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3fb20ba0ced431f8f644f966c8943f2",
            "placeholder": "​",
            "style": "IPY_MODEL_06ff06410d7a4793ace2299009fd803b",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "d3fb20ba0ced431f8f644f966c8943f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9657b19cad46e1b29b63d902c1fa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee53e5ebfd244fe2b90261d3e01b82ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3501f80829443f8b3ce326e7bcf4bae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72fdd89d2b34c00b2b1746f91a7c24d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}